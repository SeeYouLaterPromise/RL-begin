永海，我查看你上传的代码，我有如下建议：

- 叠法问题：你对于多帧堆叠的叠法是按`通道维度`堆叠的，这在语义上没有意义。有必要改成`(n_frames, C, H, W)`。详细原因见`temporal.md`。
- 时序模型：现在我们用过的模型其实就是普通的 2D 的 CNN，对于时序建模任务是不适合的。详细原因见`temporal.md`。我现在在`supervised`文件夹中添加了`model`文件夹放多个模型的代码，我已经帮你找了`TCN`的代码；请你自行去搜集 1dCNN 用来时序建模的代码实现。比较不同模型的效果。总结：
  - 单帧输入：用之前的 CNN2d （曾用名：MarioBCModel, 现名：CNN2d）
  - 多帧输入：CNN1d, TCN, 未来有兴趣拓展 RNN，LSTM，GRU（算法工程师之路）
- 工程问题：注意写代码时的**可拓展性**，比如 MarioDataset 我在设计 pure BC 和 BC with penalty 的时候是设计成可选项，供实验人员自由选择实验哪一种。你在设计多帧堆叠的时候也要注意这种选择性。另外，代码的可复用性，已经良好的代码结构、好的注释习惯也要注意培养，一个好的程序员的必经之路。
- 实验与记录对比：
  - pure BC 和 BC with penalty 的效果区别。
  - 单帧输入 与 多帧输入的效果区别。
- 说到效果：
  思考我中午与你们讨论的那种方式如何实现：利用我们采集的游戏帧（题目）与我们的定的动作编号（标准答案）让 AI 训练一个 epoch 之后，让他直接去考试：利用现有的模型参数去真实环境测试效果。我们可以考虑：AI 控制的 mario 能顺利跳过绿色管道、能顺利通过连续 4 个怪物等等这样好的行为：我们就给 mario 加“经验值”来评价 AI 学习的好坏作为下一轮训练的依据（老师根据考试情况，调整平时教学）。**注意：除必要情况外，不要删改已经存在的良好代码与注释，添加新功能请新建 py 文件。**
- 杂项：
  你提到的“过滤掉被障碍物阻挡的哪些帧，我按了移动但是却没有位置坐标变化”很好，考虑这个方向可以很好必要 mario 傻乎乎的不动或者被柱子挡着仍然向右走的卡 bug 的情况。但是**过滤**只是让 AI 不要学习到这个傻乎乎的东西。并不能避免他本来就傻乎乎，可能需要给一下错误案例让他作为反面去学习避免。
- 你和威伟互相介绍自己做的东西，尝试去训练对方的模型，多多相互交流，我们是**队友**。

威伟，请你在跟视频的同时要主动思考。考虑：

- 调查强化学习的权重文件是什么？和我们训练强监督学习得到的是 pytorch 的.py 文件有什么不同。给我们讲讲。
- 然后调用训练好的强化学习模型做推理，像我和永海做的那种效果。
- 强化学习和强监督学习的模型推理是否可以统一在一个文件？
- 中午你也提到强化学习的奖励很重要；且你现在做的是调用 stable-baseline-3 的包，看看是否我们可以自己设计奖励函数？
- 你和永海互相介绍自己做的东西，尝试去训练对方的模型，多多相互交流，我们是**队友**。
