# Begin to learn Reinforcement Learning for Super Mario

Attention: when executing `pip install -r requirements.txt`, you should quit the VPN.

## Preliminary

### Environment Configuration

Thanks for "https://www.bilibili.com/video/BV1CERYY3EjA?spm_id_from=333.788.videopod.sections&vd_source=be632c59a4ce49cc99bcd97058a50691&p=11"'s help:

```bash
conda create -n rl_mario python=3.8
conda activate rl_mario

pip install setuptools==65.5.0
pip install wheel==0.38.4
python.exe -m pip install pip==20.2.4

pip install -r requirement.txt
```

Pay attention: `gym==0.21.0` (must), if you follow the video, get the updatest version of `gym`, you will meet error like:

```
Traceback (most recent call last):
  File ".\human_op.py", line 49, in <module>
    state, _, done, _ = env.step(current_action)
  File "D:\Anaconda\envs\rl\lib\site-packages\nes_py\wrappers\joypad_space.py", line 74, in step
    return self.env.step(self._action_map[action])
  File "D:\Anaconda\envs\rl\lib\site-packages\gym\wrappers\time_limit.py", line 50, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
ValueError: not enough values to unpack (expected 5, got 4)
```

### gym

ä¸Šé¢çš„ä»£ç æ˜¯æˆ‘å†™æ¥é‡‡é›†ç©å®¶è¡Œä¸ºæ•°æ®çš„ï¼šåªæœ‰ä¸€æ¬¡æœºä¼šï¼Œæ— è®ºæ˜¯å¦é€šå…³éƒ½ä¼šç»“æŸæ•°æ®é‡‡é›†ã€‚ä½†æ˜¯ï¼Œæˆ‘æƒ³æ ¹æ®ç©å®¶æ˜¯å¦é€šå…³ç»™ trajectory.json å‘½åä¸º trajectory_success.json æˆ– trajectory_failure.jsonã€‚æˆ‘åŸæœ¬æƒ³é€šè¿‡ info.['life']æ¥å®ç°ï¼Œä½†æ˜¯æµ‹è¯•å‘ç°ä¸å¥æ•ˆï¼Œè¯·ä½ å¸®æˆ‘æƒ³æƒ³åŠæ³•ã€‚ä¸‹é¢æ˜¯ info çš„å†…å®¹ç»“æ„ï¼š

```
reward: 0.0,
done: False,
info: {
  'coins': 0,
  'flag_get': False,
  'life': 2,
  'score': 0,
  'stage': 1,
  'status': 'small',
  'time': 341, 'world': 1, 'x_pos': 40, 'x_pos_screen': 40, 'y_pos': 79}
```

| é”®                 | å«ä¹‰                              |
| ------------------ | --------------------------------- |
| `info['flag_get']` | âœ… ç©å®¶æ˜¯å¦æˆåŠŸè·³åˆ°æ——æ†ï¼ˆå³é€šå…³ï¼‰ |
| `info['life']`     | ä»…å½“æ­»äº¡æ—¶å¶å°”æ›´æ–°ï¼Œä½†æœ‰å»¶è¿Ÿ      |
| `info['status']`   | `small`, `big`, `fireball` çŠ¶æ€   |
| `done`             | æ¸¸æˆæ˜¯å¦ç»“æŸï¼ˆå¯èƒ½æ˜¯æ­»äº¡/é€šå…³ï¼‰   |

### ğŸ® game handle buttons controlling

åœ¨é©¬é‡Œå¥¥ NES æ¸¸æˆï¼ˆä¹Ÿå°±æ˜¯ä»»å¤©å ‚çº¢ç™½æœºä¸Šçš„ç»å…¸ã€ŠSuper Mario Bros.ã€‹ï¼‰ä¸­ï¼Œ**`A` å’Œ `B` æ˜¯æ¸¸æˆæ‰‹æŸ„ä¸Šçš„ä¸¤ä¸ªä¸»è¦åŠ¨ä½œæŒ‰é’®**ã€‚å®ƒä»¬å¯¹åº”çš„åŠŸèƒ½å¦‚ä¸‹ï¼š

| æŒ‰é’® | ä½œç”¨                    | åœ¨é©¬é‡Œå¥¥ä¸­çš„å®é™…æ•ˆæœ                             |
| ---- | ----------------------- | ------------------------------------------------ |
| `A`  | **è·³è·ƒï¼ˆJumpï¼‰**        | æ§åˆ¶é©¬é‡Œå¥¥è·³èµ·æ¥                                 |
| `B`  | **åŠ é€Ÿï¼ˆRunï¼‰æˆ–å°„ç«çƒ** | è·‘æ­¥åŠ é€Ÿã€æ¸¸æ³³æ—¶åŠ é€Ÿã€å‘å°„ç«çƒï¼ˆå¦‚æœæœ‰ç«çƒèƒ½åŠ›ï¼‰ |

---

### Keyboard buttons controlling

`human_op.py` can provide you with mario playing.

> ğŸ® æ§åˆ¶è¯´æ˜ï¼šD=å³, A=å·¦, K=è·³, J=åŠ é€Ÿ, W=ä¸Š, S=ä¸‹ï¼Œæ”¯æŒç»„åˆé”®ï¼Œå¦‚ D+K

## Task Allocation

### work zone

- `Supervised` (Yonghai Yue)
- `Unsupervised` (Weiwei Lin)
- `Semi-supervised` (Yexin Liu Lu)

## Supervised Learning

input: game frame

output: action_id

### Data Collection

`collect_data.py`: Designed for collecting data.

é‡‡é›†ä½¿ç”¨é¡»çŸ¥ï¼š

- ä½ å¯ä»¥è‡ªå·±**è®¾å®šå…³å¡**è¿›è¡Œæ”¶é›†è®­ç»ƒæ•°æ®ã€‚
- æ¯å½“**é€šå…³**æˆ–**æ­»äº¡**ä¼šç»“æŸæ•°æ®é‡‡é›†ã€‚
- é€šå…³å`trajectory.json`ä¼šè¢«æ ‡æ³¨ä¸º successã€‚

é‡‡é›†æ•°æ®è®¾ç½®ï¼š

- grayscale
- resize: `RESIZE_SHAPE = (84, 84)`
- frame skipping / subsampling: `FRAME_SKIP = 4 `
- recording after first moving: æ£€æŸ¥æ˜¯å¦å¼€å§‹é‡‡é›†: ç©å®¶å¼€å§‹ç§»åŠ¨ï¼Œå¼€å§‹é‡‡é›†æ•°æ®

æ•°æ®é›†æ–‡ä»¶å¤¹ç»“æ„ï¼š

```
supervised/
â””â”€â”€ mario_data/ --------------- Total
    â”œâ”€â”€ 1-1/  ----------------- Level (å…³å¡)
    â”‚   â”œâ”€â”€ 10-12-37/ --------- Exp   (å®éªŒ)
    â”‚   â”‚   â”œâ”€â”€ frames/ ------- Image
    â”‚   â”‚   â””â”€â”€ trajectory_success.json ---------- (é€šå…³ç»“æŸ)
    â”‚   â”œâ”€â”€ 11-09-05/
    â”‚   â”‚   â”œâ”€â”€ frames/
    â”‚   â”‚   â””â”€â”€ trajectory_failure.json ---------- (æ­»äº¡ç»“æŸ/æ‰‹åŠ¨é€€å‡º)
    â”œâ”€â”€ 1-2/
    â”‚   â””â”€â”€ 10-13-00/
    â”‚       â”œâ”€â”€ frames/
    â”‚       â””â”€â”€ trajectory_success.json
```

`MarioDataset.py` defines the `MarioDataset` class and the `train_val_split` function, both of which are used for data preparation prior to training.

æˆ‘ç°åœ¨å·²ç»å®ç°äº†ä¸‹é¢çš„æ•°æ®é›†æ–‡ä»¶å¤¹ç»“æ„ï¼Œå°†æ˜¯å¦å­˜åœ¨æ­»äº¡å¸§çš„å®éªŒè®°å½•æ ‡æ³¨å¤„ç†ï¼ˆé€šè¿‡å‘½å json æ–‡ä»¶ï¼‰trajectory_failure.json ä¸­æœ€åä¸€æ¡æ•°æ®çš„ is_dead ä¸º trueï¼Œå³æ­»äº¡å¸§ã€‚æˆ‘ç°åœ¨åœ¨æ€è€ƒï¼šæ­»äº¡å¸§æ˜¯ä¸æ˜¯ç”±äºåœ¨æ­»äº¡å¸§å‘ç”Ÿçš„å‰ä¸€æ®µæ—¶é—´ç©å®¶çš„é”™è¯¯åˆ¤æ–­å¯¼è‡´çš„ï¼Œæ‰€ä»¥è¿™äº›å¸§æ˜¯ä¸æ˜¯ä¹Ÿè¦è®© agent ä½œä¸ºåé¢æ•™æå­¦ä¹ ï¼Ÿè€ƒè™‘åˆ°äººçš„ååº”æ—¶é—´ï¼ˆå‡è®¾ 1sï¼‰ï¼Œè·³å¸§ï¼ˆ4 å¸§ï¼‰å’Œå¸§ç‡ï¼ˆFPS=60ï¼‰ï¼Œæ‰€ä»¥æ­»äº¡å¸§å‰ 15 å¸§æ˜¯å¦éœ€è¦è®© agent ä½œä¸ºåé¢æ•™æå­¦ä¹ ï¼Ÿ

### Training

`MarioTrainer.py` implements a subclass of `ClassifyTrainBase` with built-in functionalities for logging and plotting during training.

## Unsupervised

## Semi-supervised

```

```
